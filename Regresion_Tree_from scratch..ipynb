{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,feature = None,threshold = None,left = None,right = None,*,value= None,n_value=None) -> None:\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return not self.value is None\n",
    "    \n",
    "def mean_square_error(y_pred,y):\n",
    "    return np.average((y_pred-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self,min_samples_split =15 ,max_depth = 4 ,n_features = 0 ,root = None) -> None:\n",
    "        \n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = root\n",
    "        self.features_importance = {}\n",
    "    \n",
    "    def __calulate_variance(self,y):\n",
    "        var = np.var(y.to_numpy().flatten())\n",
    "        return var\n",
    "    \n",
    "    def __split_data(self,X,threshold):\n",
    "        #น้อยกว่าอยู่ซ้าย\n",
    "        \n",
    "        left_idxs = X[X<=threshold].index\n",
    "        right_idxs = X[X>threshold].index\n",
    "        \n",
    "        return left_idxs,right_idxs\n",
    "        \n",
    "    def __information_gain(self,X,threshold,y):\n",
    "        #parant entropy\n",
    "        parent_entropy = self.__calulate_variance(y)\n",
    "\n",
    "        left_idxs,right_idxs = self.__split_data(X,threshold)\n",
    "        \n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        n = len(y)\n",
    "        n_l , n_r =  len(left_idxs), len(right_idxs)\n",
    "        e_l , e_r = self.__calulate_variance(y.loc[list(left_idxs)]), self.__calulate_variance(y.loc[list(right_idxs)])\n",
    "        \n",
    "        child_entropy = (n_l/n)*e_l + (n_r/n)*e_r\n",
    "        \n",
    "        # calculate the information gain\n",
    "        \n",
    "        information_gain = parent_entropy - child_entropy\n",
    "            \n",
    "        return information_gain\n",
    "    \n",
    "    \n",
    "    def __update_features_importance(self,best_feature,best_threshold,depth):\n",
    "        \n",
    "        if not self.features_importance.get(depth):\n",
    "            self.features_importance[depth] = [[best_feature,best_threshold]]\n",
    "        else:\n",
    "            self.features_importance[depth].append([best_feature,best_threshold])\n",
    "            \n",
    "        \n",
    "        \n",
    "    def __best_split(self,X,y):\n",
    "        stop_split = False\n",
    "        best_ig = 0\n",
    "        features_name = X.columns\n",
    "        best_feature = 'Not found'\n",
    "        best_threshold = 'Not found'\n",
    "        for feature_name in features_name:\n",
    "            for threshold in np.unique(X[feature_name]):\n",
    "                    \n",
    "                ig = self.__information_gain(X[feature_name],threshold,y)\n",
    "                \n",
    "                if ig > best_ig:\n",
    "                    best_ig = ig\n",
    "                    best_threshold = threshold\n",
    "                    best_feature = feature_name\n",
    "                    print(f'best_feature best_threshold {best_feature} {best_threshold}') if self.verbose == 2 else ''\n",
    "                    if self.verbose == 2: print(f'current information gain = {best_ig}')\n",
    "                    \n",
    "        if self.verbose == 2: print(f'best information gain = {best_ig}')\n",
    "        \n",
    "        if best_ig == 0:\n",
    "            stop_split = True\n",
    "            print('early stop : best_ig = 0')\n",
    "            return None,None,stop_split\n",
    "        print(f'best_feature,best_threshold {best_feature,best_threshold}\\n')if self.verbose else ''\n",
    "        \n",
    "        return best_feature,best_threshold,stop_split\n",
    "        \n",
    "    @staticmethod\n",
    "    def __most_common_label(y):\n",
    "        av = np.average(y.to_numpy().flatten())\n",
    "        # print(av)\n",
    "        return av\n",
    "    \n",
    "    \n",
    "    def __grow_tree(self,X,y,current_depth=0):\n",
    "        \n",
    "        if (current_depth>self.max_depth) or (len(X.columns) == 0) or (len(np.unique(y)) == 1):\n",
    "            if current_depth>self.max_depth:print(\"max depth reach\")\n",
    "            return Node(value=self.__most_common_label(y),n_value=len(y))\n",
    "        \n",
    "        print(f'current depth = {current_depth}') if self.verbose else ''\n",
    "        \n",
    "        best_feature,best_threshold,stop_grow =self.__best_split(X,y)\n",
    "        \n",
    "        if stop_grow:return Node(value=self.__most_common_label(y),n_value=len(y))\n",
    "        \n",
    "        left_idxs,right_idxs = self.__split_data(X[best_feature],best_threshold)\n",
    "        \n",
    "        if len(left_idxs) < self.min_samples_split or len(right_idxs) < self.min_samples_split:\n",
    "            print(\"min samples split reach\")\n",
    "            return Node(value=self.__most_common_label(y),n_value=len(y))\n",
    "       \n",
    "        self.__update_features_importance(best_feature,best_threshold,current_depth) \n",
    "        \n",
    "        left = self.__grow_tree(X.drop(best_feature,axis=1).loc[left_idxs],y.loc[left_idxs],current_depth+1)\n",
    "\n",
    "        right = self.__grow_tree(X.drop(best_feature,axis=1).loc[right_idxs],y.loc[right_idxs],current_depth+1)\n",
    "        \n",
    "        \n",
    "        return Node(best_feature,best_threshold,left,right)\n",
    "    \n",
    "    def fit(self,X,y,verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.n_features = X.shape[1]\n",
    "        self.features_name = X.columns\n",
    "        self.root = self.__grow_tree(X,y)\n",
    "        \n",
    "        predictions_train = self.predict(X)\n",
    "        print('mean_square_error : ',mean_square_error(y.to_numpy().flatten(),self.predict(X)))\n",
    "        \n",
    "    def __traverse_tree(self,X,node:Node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        if X[node.feature] <= node.threshold:\n",
    "            return self.__traverse_tree(X,node.left)\n",
    "        \n",
    "        return self.__traverse_tree(X,node.right)\n",
    "              \n",
    "    def predict(self,X):\n",
    "        return np.array([self.__traverse_tree(x[1],self.root) for x in X.iterrows()])\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "x = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "y = pd.DataFrame(data.target,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018118  0.044485  \n",
       "439 -0.011080 -0.046879  0.015491  \n",
       "440  0.026560  0.044528 -0.025930  \n",
       "441 -0.039493 -0.004220  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min samples split reach\n",
      "min samples split reach\n",
      "min samples split reach\n",
      "min samples split reach\n",
      "min samples split reach\n",
      "mean_square_error :  3283.6870038055476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2 ,random_state=42)\n",
    "\n",
    "clf = DecisionTree(min_samples_split=5,max_depth=10)\n",
    "clf.fit(X_train,y_train,verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_mean_square_error :  3283.6870038055476\n",
      "test_mean_square_error :  3259.7975547678784\n"
     ]
    }
   ],
   "source": [
    "predictions_train = clf.predict(X_train)\n",
    "predictions_test = clf.predict(X_test)\n",
    "\n",
    "print('train_mean_square_error : ',mean_square_error(y_train.to_numpy().flatten(),predictions_train))\n",
    "print('test_mean_square_error : ',mean_square_error(y_test.to_numpy().flatten(),predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [['bmi', 0.00457216660300077]],\n",
       " 1: [['s5', 0.00538436996854573], ['s6', 0.0320591578182113]],\n",
       " 2: [['bp', 0.0597439326260547]]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.features_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([164.66666667, 175.475     , 164.66666667, 243.        ,\n",
       "       100.55921053, 100.55921053, 175.475     , 243.        ,\n",
       "       164.66666667, 175.475     , 100.55921053, 164.66666667,\n",
       "       100.55921053, 243.        , 100.55921053, 175.475     ,\n",
       "       243.        , 243.        , 243.57142857, 243.57142857,\n",
       "       175.475     , 100.55921053, 100.55921053, 175.475     ,\n",
       "       175.475     , 175.475     , 175.475     , 100.55921053,\n",
       "       100.55921053, 100.55921053, 175.475     , 100.55921053,\n",
       "       175.475     , 164.66666667, 175.475     , 175.475     ,\n",
       "       164.66666667, 164.66666667, 164.66666667, 100.55921053,\n",
       "       100.55921053, 100.55921053, 100.55921053, 164.66666667,\n",
       "       164.66666667, 100.55921053, 100.55921053, 100.55921053,\n",
       "       100.55921053, 164.66666667, 175.475     , 100.55921053,\n",
       "       175.475     , 100.55921053, 164.66666667, 175.475     ,\n",
       "       100.55921053, 175.475     , 100.55921053, 100.55921053,\n",
       "       175.475     , 175.475     , 175.475     , 100.55921053,\n",
       "       164.66666667, 243.57142857, 164.66666667, 164.66666667,\n",
       "       100.55921053, 164.66666667, 164.66666667, 175.475     ,\n",
       "       164.66666667, 100.55921053, 100.55921053, 164.66666667,\n",
       "       243.        , 175.475     , 175.475     , 164.66666667,\n",
       "       100.55921053, 100.55921053, 100.55921053, 100.55921053,\n",
       "       100.55921053, 100.55921053, 100.55921053, 100.55921053,\n",
       "       175.475     ])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
