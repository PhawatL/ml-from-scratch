{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smy6UckQ3YfA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erPtjOt_ml-P"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(model, X, y):\n",
        "    # Set min and max values and give it some padding\n",
        "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
        "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
        "    h = 0.01\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    # Predict the function value for the whole grid\n",
        "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # Plot the contour and training examples\n",
        "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
        "    plt.ylabel('x2')\n",
        "    plt.xlabel('x1')\n",
        "    plt.scatter(X[0, :], X[1, :], c=y, cmap=plt.cm.Spectral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81K5S8w73gV5"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXSXEsFq_TRJ",
        "outputId": "3f874bca-49ed-45fd-9c11-776a01e7e886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['feature_names']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UtFWysvi63K",
        "outputId": "fe4fb9d3-7003-489c-e8fa-265958710459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ],
      "source": [
        "print(dataset.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD3r2xLb-9jy",
        "outputId": "24571014-340b-49bf-8560-a0ab14ac3592"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['target_names']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQv4hatId1GC",
        "outputId": "05d0282c-1c13-4337-c246-c3b5e0868ea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1.361e+01, 2.498e+01, 8.805e+01, 5.827e+02, 9.488e-02, 8.511e-02,\n",
              "        8.625e-02, 4.489e-02, 1.609e-01, 5.871e-02, 4.565e-01, 1.290e+00,\n",
              "        2.861e+00, 4.314e+01, 5.872e-03, 1.488e-02, 2.647e-02, 9.921e-03,\n",
              "        1.465e-02, 2.355e-03, 1.699e+01, 3.527e+01, 1.086e+02, 9.065e+02,\n",
              "        1.265e-01, 1.943e-01, 3.169e-01, 1.184e-01, 2.651e-01, 7.397e-02]), 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['data'][100],dataset['target'][100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLfU524kAQEy",
        "outputId": "38d0e8db-dc89-4cdb-c8be-8a31532db596"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBDP9xKn3qty"
      },
      "outputs": [],
      "source": [
        "X , Y = dataset['data'],dataset['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnZAEtzfjdub",
        "outputId": "1a946915-a9a2-4be6-af2f-0be863d64445"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1.504e+01, 1.674e+01, 9.873e+01, 6.894e+02, 9.883e-02, 1.364e-01,\n",
              "        7.721e-02, 6.142e-02, 1.668e-01, 6.869e-02, 3.720e-01, 8.423e-01,\n",
              "        2.304e+00, 3.484e+01, 4.123e-03, 1.819e-02, 1.996e-02, 1.004e-02,\n",
              "        1.055e-02, 3.237e-03, 1.676e+01, 2.043e+01, 1.097e+02, 8.569e+02,\n",
              "        1.135e-01, 2.176e-01, 1.856e-01, 1.018e-01, 2.177e-01, 8.549e-02]), 1)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[500],Y[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpzo-_gz89QJ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGjU1c8SLlHR",
        "outputId": "86d8010c-4258-44f3-cce8-5f3b94c1f2ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((455, 30), (114, 30), (455,), (114,))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfjt8aokIavv",
        "outputId": "f5c1e61a-c022-44e6-8a41-572bd1ee45d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-d3092c2cc0b3>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y[y>1] = 1\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:8870: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return self._update_inplace(result)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\",header=None)\n",
        "df.columns = ['age','sex','cp','restbp','chol','fbs','restecg','thalech','exang','oldpeak','slope','ca','thal','hd']\n",
        "df_nomissing = df.loc[(df['ca']!='?')&(df['thal'] != '?')]\n",
        "X = df_nomissing.drop('hd',axis=1)\n",
        "y = df_nomissing['hd']\n",
        "y[y>1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uMwY3YelIsvX",
        "outputId": "b0a9e068-5a19-43be-db45-e6df21b15058"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f19d4387-0eac-4d49-ba9b-dabfd0cbaf5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>restbp</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>thalech</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>cp_1.0</th>\n",
              "      <th>cp_2.0</th>\n",
              "      <th>...</th>\n",
              "      <th>slope_1.0</th>\n",
              "      <th>slope_2.0</th>\n",
              "      <th>slope_3.0</th>\n",
              "      <th>thal_3.0</th>\n",
              "      <th>thal_6.0</th>\n",
              "      <th>thal_7.0</th>\n",
              "      <th>ca_0.0</th>\n",
              "      <th>ca_1.0</th>\n",
              "      <th>ca_2.0</th>\n",
              "      <th>ca_3.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>45.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>57.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>57.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>297 rows Ã— 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f19d4387-0eac-4d49-ba9b-dabfd0cbaf5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f19d4387-0eac-4d49-ba9b-dabfd0cbaf5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f19d4387-0eac-4d49-ba9b-dabfd0cbaf5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      age  sex  restbp   chol  fbs  thalech  exang  oldpeak  cp_1.0  cp_2.0  \\\n",
              "0    63.0  1.0   145.0  233.0  1.0    150.0    0.0      2.3       1       0   \n",
              "1    67.0  1.0   160.0  286.0  0.0    108.0    1.0      1.5       0       0   \n",
              "2    67.0  1.0   120.0  229.0  0.0    129.0    1.0      2.6       0       0   \n",
              "3    37.0  1.0   130.0  250.0  0.0    187.0    0.0      3.5       0       0   \n",
              "4    41.0  0.0   130.0  204.0  0.0    172.0    0.0      1.4       0       1   \n",
              "..    ...  ...     ...    ...  ...      ...    ...      ...     ...     ...   \n",
              "297  57.0  0.0   140.0  241.0  0.0    123.0    1.0      0.2       0       0   \n",
              "298  45.0  1.0   110.0  264.0  0.0    132.0    0.0      1.2       1       0   \n",
              "299  68.0  1.0   144.0  193.0  1.0    141.0    0.0      3.4       0       0   \n",
              "300  57.0  1.0   130.0  131.0  0.0    115.0    1.0      1.2       0       0   \n",
              "301  57.0  0.0   130.0  236.0  0.0    174.0    0.0      0.0       0       1   \n",
              "\n",
              "     ...  slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  \\\n",
              "0    ...          0          0          1         0         1         0   \n",
              "1    ...          0          1          0         1         0         0   \n",
              "2    ...          0          1          0         0         0         1   \n",
              "3    ...          0          0          1         1         0         0   \n",
              "4    ...          1          0          0         1         0         0   \n",
              "..   ...        ...        ...        ...       ...       ...       ...   \n",
              "297  ...          0          1          0         0         0         1   \n",
              "298  ...          0          1          0         0         0         1   \n",
              "299  ...          0          1          0         0         0         1   \n",
              "300  ...          0          1          0         0         0         1   \n",
              "301  ...          0          1          0         1         0         0   \n",
              "\n",
              "     ca_0.0  ca_1.0  ca_2.0  ca_3.0  \n",
              "0         1       0       0       0  \n",
              "1         0       0       0       1  \n",
              "2         0       0       1       0  \n",
              "3         1       0       0       0  \n",
              "4         1       0       0       0  \n",
              "..      ...     ...     ...     ...  \n",
              "297       1       0       0       0  \n",
              "298       1       0       0       0  \n",
              "299       0       0       1       0  \n",
              "300       0       1       0       0  \n",
              "301       0       1       0       0  \n",
              "\n",
              "[297 rows x 25 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = X.astype(float)\n",
        "X_encoded = pd.get_dummies(X,columns=['cp','restecg','slope','thal','ca'])\n",
        "X_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgatINlzIuLV",
        "outputId": "1bb48221-4905-4c83-8d4e-bc2521d9061b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      1\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "297    1\n",
              "298    1\n",
              "299    1\n",
              "300    1\n",
              "301    1\n",
              "Name: hd, Length: 297, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X69o_OvmI2Cu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded.to_numpy(), y.to_numpy(), test_size=0.2, random_state=69)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ritANrhGKy_D",
        "outputId": "7f8f4ca9-98eb-4aec-e608-381b4034b314"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 50.,   1., 129., ...,   0.,   0.,   0.],\n",
              "       [ 41.,   0., 126., ...,   0.,   0.,   0.],\n",
              "       [ 39.,   0.,  94., ...,   0.,   0.,   0.],\n",
              "       ...,\n",
              "       [ 61.,   1., 120., ...,   1.,   0.,   0.],\n",
              "       [ 58.,   1., 128., ...,   0.,   1.,   0.],\n",
              "       [ 60.,   1., 130., ...,   1.,   0.,   0.]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vDK7iGdJ6iu",
        "outputId": "ed77a01e-c120-4c58-955a-71b6dc8e698b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGgIjutIj-T7"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XlV_8w7Gj_Ji",
        "outputId": "4fa1198a-86a6-45a8-edc2-83d7f0e6712c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.linspace(-10,10,20),sigmoid(np.linspace(-10,10,20)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1_1wVXF6pIq"
      },
      "source": [
        "$$J = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\ln\\left(y\\_pred^{ (i)}\\right) + (1-y^{(i)})\\ln\\left(1- y\\_pred^{ (i)}\\right) \\large{)} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWeolWjP4eYZ"
      },
      "outputs": [],
      "source": [
        "def LogisticRegressions(X,Y,x,y,lr = 1e-4 , n = 1000,*,gramma = 0.9,verbose=10,momentum = False,predict = False):\n",
        "  if verbose < 0: verbose =n\n",
        "  m , dim = X.shape\n",
        "  w = np.zeros((dim,1))\n",
        "  log = {'epochs':[],'acc_train':[],'acc_test':[]}\n",
        "  b = 0\n",
        "  vw = 0\n",
        "  vb = 0\n",
        "  for i in range(n):\n",
        "    z = np.dot(w.T,X.T) + b\n",
        "    y_pred = sigmoid(z)\n",
        "    cost = np.sum(((- np.log(y_pred))*Y + (-np.log(1-y_pred))*(1-Y)))/m\n",
        "    dw = (np.dot(X.T,(y_pred-Y).T))/m\n",
        "    db =(np.sum((y_pred-Y)))/m\n",
        "    if momentum:\n",
        "      vw = (gramma)*vw + lr*dw\n",
        "      vb = (gramma)*vb + lr*db\n",
        "      w = w - vw\n",
        "      b = b - vb\n",
        "    else:\n",
        "      w = w - lr*dw\n",
        "      b = b - lr*db\n",
        "    if (i+1) % (n // verbose) == 0 or (i+1) == 1 or (i+1) == n:\n",
        "      ans = np.round(y_pred)\n",
        "      acc = np.mean(ans == Y)\n",
        "      z = np.dot(w.T,x.T) +b\n",
        "      test_pred = sigmoid(z)\n",
        "      ans = np.round(test_pred)\n",
        "      print(f'epoch {i+1:^4} : accuracy_train = {acc*100:.3f} %    accuracy_test = {np.mean(ans == y)*100:.3f} %   loss = {cost:.10f}')\n",
        "      log['acc_train'].append(acc*100)\n",
        "      log['acc_test'].append(np.mean(ans == y)*100)\n",
        "      log['epochs'].append(i+1)\n",
        "  return (w,b,log)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5H53TXzBLJK"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, lr=1e-4, n=1000, gramma=0.9, verbose=10, momentum=False):\n",
        "        self.lr = lr\n",
        "        self.n = n\n",
        "        self.gramma = gramma\n",
        "        self.verbose = verbose\n",
        "        self.momentum = momentum\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "        self.log = None\n",
        "    \n",
        "    def fit(self, X, Y,*,random_state= 42,test_size=0.2):\n",
        "        X, x, Y, y = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
        "        if self.verbose < 0:\n",
        "            self.verbose = self.n\n",
        "        m, dim = X.shape\n",
        "        self.w = np.zeros((dim, 1))\n",
        "        self.b = 0\n",
        "        vw = 0\n",
        "        vb = 0\n",
        "        self.log = {'epochs': [], 'acc_train': [], 'acc_test': []}\n",
        "        for i in range(self.n):\n",
        "            z = np.dot(self.w.T, X.T) + self.b\n",
        "            y_pred = sigmoid(z)\n",
        "            cost_train = np.sum(((- np.log(y_pred))*Y + (-np.log(1-y_pred))*(1-Y)))/m\n",
        "            dw = (np.dot(X.T, (y_pred-Y).T))/m\n",
        "            db = (np.sum((y_pred-Y)))/m\n",
        "            if self.momentum:\n",
        "                vw = (self.gramma)*vw + self.lr*dw\n",
        "                vb = (self.gramma)*vb + self.lr*db\n",
        "                self.w = self.w - vw\n",
        "                self.b = self.b - vb\n",
        "            else:\n",
        "                self.w = self.w - self.lr*dw\n",
        "                self.b = self.b - self.lr*db\n",
        "            if (i+1) % (self.n // self.verbose) == 0 or (i+1) == 1 or (i+1) == self.n:\n",
        "                ans = np.round(y_pred)\n",
        "                acc_train = np.mean(ans == Y)\n",
        "                self.log['acc_train'].append(acc_train*100)\n",
        "                self.log['epochs'].append(i+1)\n",
        "                \n",
        "                z = np.dot(self.w.T, x.T) + self.b\n",
        "                test_pred = sigmoid(z)\n",
        "                ans = np.round(test_pred)\n",
        "                acc_test = np.mean(ans == y)\n",
        "                self.log['acc_test'].append(acc_test*100)         \n",
        "                print(f'epoch {i+1:^4} : accuracy_train = {acc_train*100:.3f} %    accuracy_test = {acc_test*100:.3f} %   loss_train = {cost_train:.10f}')\n",
        "        return (w,b,log)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        z = np.dot(self.w.T, x.T) + self.b\n",
        "        test_pred = sigmoid(z)\n",
        "        ans = np.round(test_pred)\n",
        "        return ans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WQR8k32lUHy",
        "outputId": "ee3e9e6b-1cdf-447d-c627-3317807babb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0., 0., 1.])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.round([0.51,0.5,0.1,0.8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qBvzWvHFVbo",
        "outputId": "08cd90ea-a2a2-4a8e-b371-5e82d4cdc7e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  1   : accuracy_train = 50.211 %    accuracy_test = 73.333 %   loss = 0.6931471806\n",
            "epoch 750  : accuracy_train = 82.278 %    accuracy_test = 81.667 %   loss = 0.4104329879\n",
            "epoch 1500 : accuracy_train = 85.232 %    accuracy_test = 85.000 %   loss = 0.3497348501\n",
            "epoch 2250 : accuracy_train = 86.076 %    accuracy_test = 83.333 %   loss = 0.3331038132\n",
            "epoch 3000 : accuracy_train = 88.186 %    accuracy_test = 81.667 %   loss = 0.3215591665\n",
            "epoch 3750 : accuracy_train = 87.764 %    accuracy_test = 81.667 %   loss = 0.3162739361\n",
            "epoch 4500 : accuracy_train = 87.342 %    accuracy_test = 83.333 %   loss = 0.3114222962\n",
            "epoch 5250 : accuracy_train = 86.920 %    accuracy_test = 81.667 %   loss = 0.3077714844\n",
            "epoch 6000 : accuracy_train = 87.764 %    accuracy_test = 80.000 %   loss = 0.3058993955\n",
            "epoch 6750 : accuracy_train = 87.764 %    accuracy_test = 78.333 %   loss = 0.3047714818\n",
            "epoch 7500 : accuracy_train = 87.764 %    accuracy_test = 78.333 %   loss = 0.3039638175\n",
            "epoch 8250 : accuracy_train = 87.342 %    accuracy_test = 78.333 %   loss = 0.3034159248\n",
            "epoch 9000 : accuracy_train = 87.342 %    accuracy_test = 78.333 %   loss = 0.3029904378\n",
            "epoch 9750 : accuracy_train = 87.342 %    accuracy_test = 78.333 %   loss = 0.3026328290\n",
            "epoch 10500 : accuracy_train = 87.342 %    accuracy_test = 78.333 %   loss = 0.3023351352\n",
            "epoch 11250 : accuracy_train = 87.342 %    accuracy_test = 78.333 %   loss = 0.3020799299\n",
            "epoch 12000 : accuracy_train = 87.342 %    accuracy_test = 78.333 %   loss = 0.3018576938\n",
            "epoch 12750 : accuracy_train = 87.764 %    accuracy_test = 78.333 %   loss = 0.3016647075\n",
            "epoch 13500 : accuracy_train = 87.764 %    accuracy_test = 78.333 %   loss = 0.3014961846\n",
            "epoch 14250 : accuracy_train = 87.764 %    accuracy_test = 78.333 %   loss = 0.3013480935\n",
            "epoch 15000 : accuracy_train = 87.764 %    accuracy_test = 78.333 %   loss = 0.3012175792\n"
          ]
        }
      ],
      "source": [
        "w,b,log = LogisticRegressions(X_train,y_train,X_test,y_test,lr = 2e-5 , n = 15000 ,gramma=0.999,verbose = 20, momentum = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhf-tGFNBbli",
        "outputId": "49519c24-2de9-4383-a4a8-7266f54bb86f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  1   : accuracy_train = 38.462 %    accuracy_test = 31.868 %   loss_train = 0.6931471806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-30aa1bb70e44>:25: RuntimeWarning: divide by zero encountered in log\n",
            "  cost_train = np.sum(((- np.log(y_pred))*Y + (-np.log(1-y_pred))*(1-Y)))/m\n",
            "<ipython-input-22-30aa1bb70e44>:25: RuntimeWarning: invalid value encountered in multiply\n",
            "  cost_train = np.sum(((- np.log(y_pred))*Y + (-np.log(1-y_pred))*(1-Y)))/m\n",
            "<ipython-input-19-bb43d9876711>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1+np.exp(-x))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2000 : accuracy_train = 90.659 %    accuracy_test = 90.110 %   loss_train = nan\n",
            "epoch 4000 : accuracy_train = 90.659 %    accuracy_test = 91.209 %   loss_train = 0.4622051039\n",
            "epoch 6000 : accuracy_train = 94.505 %    accuracy_test = 91.209 %   loss_train = 0.2335563897\n",
            "epoch 8000 : accuracy_train = 95.879 %    accuracy_test = 95.604 %   loss_train = 0.0996441845\n",
            "epoch 10000 : accuracy_train = 96.429 %    accuracy_test = 93.407 %   loss_train = 0.0871147651\n",
            "epoch 12000 : accuracy_train = 95.879 %    accuracy_test = 94.505 %   loss_train = 0.0818056419\n",
            "epoch 14000 : accuracy_train = 96.154 %    accuracy_test = 94.505 %   loss_train = 0.0789886754\n",
            "epoch 16000 : accuracy_train = 96.154 %    accuracy_test = 94.505 %   loss_train = 0.0768320214\n",
            "epoch 18000 : accuracy_train = 96.429 %    accuracy_test = 94.505 %   loss_train = 0.0749483058\n",
            "epoch 20000 : accuracy_train = 96.429 %    accuracy_test = 94.505 %   loss_train = 0.0732603586\n",
            "epoch 22000 : accuracy_train = 96.429 %    accuracy_test = 94.505 %   loss_train = 0.0717352071\n",
            "epoch 24000 : accuracy_train = 96.703 %    accuracy_test = 94.505 %   loss_train = 0.0703487392\n",
            "epoch 26000 : accuracy_train = 96.978 %    accuracy_test = 94.505 %   loss_train = 0.0690820251\n",
            "epoch 28000 : accuracy_train = 96.978 %    accuracy_test = 94.505 %   loss_train = 0.0679199109\n",
            "epoch 30000 : accuracy_train = 97.253 %    accuracy_test = 94.505 %   loss_train = 0.0668499614\n",
            "epoch 32000 : accuracy_train = 97.253 %    accuracy_test = 94.505 %   loss_train = 0.0658617791\n",
            "epoch 34000 : accuracy_train = 97.253 %    accuracy_test = 94.505 %   loss_train = 0.0649465484\n",
            "epoch 36000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0640967076\n",
            "epoch 38000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0633057098\n",
            "epoch 40000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0625678438\n",
            "epoch 42000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0618780965\n",
            "epoch 44000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0612320451\n",
            "epoch 46000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0606257708\n",
            "epoch 48000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0600557887\n",
            "epoch 50000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0595189906\n",
            "epoch 52000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0590125957\n",
            "epoch 54000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0585341106\n",
            "epoch 56000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0580812943\n",
            "epoch 58000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0576521280\n",
            "epoch 60000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0572447901\n",
            "epoch 62000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0568576332\n",
            "epoch 64000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0564891651\n",
            "epoch 66000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0561380317\n",
            "epoch 68000 : accuracy_train = 97.802 %    accuracy_test = 94.505 %   loss_train = 0.0558030019\n",
            "epoch 70000 : accuracy_train = 97.527 %    accuracy_test = 94.505 %   loss_train = 0.0554829551\n",
            "epoch 72000 : accuracy_train = 97.527 %    accuracy_test = 95.604 %   loss_train = 0.0551768690\n",
            "epoch 74000 : accuracy_train = 97.527 %    accuracy_test = 95.604 %   loss_train = 0.0548838099\n",
            "epoch 76000 : accuracy_train = 97.527 %    accuracy_test = 95.604 %   loss_train = 0.0546029237\n",
            "epoch 78000 : accuracy_train = 97.527 %    accuracy_test = 95.604 %   loss_train = 0.0543334275\n",
            "epoch 80000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0540746032\n",
            "epoch 82000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0538257907\n",
            "epoch 84000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0535863828\n",
            "epoch 86000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0533558195\n",
            "epoch 88000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0531335844\n",
            "epoch 90000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0529192001\n",
            "epoch 92000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0527122249\n",
            "epoch 94000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0525122496\n",
            "epoch 96000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0523188945\n",
            "epoch 98000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0521318071\n",
            "epoch 100000 : accuracy_train = 97.802 %    accuracy_test = 95.604 %   loss_train = 0.0519506594\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression(lr = 2e-5 , n = 100000 ,gramma=0.999,verbose = 50, momentum = True)\n",
        "w,b,log = model.fit(X_train,y_train,random_state= 10,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh6ZmU_fKrpv"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzzpvq4yFzTA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(log['epochs'],log['acc_train'])\n",
        "plt.plot(log['epochs'],log['acc_test'],'orange')\n",
        "plt.legend(['train','test'])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExO7D-d5C-p7"
      },
      "outputs": [],
      "source": [
        "(sum(model.predict(X)[0] == Y)/len(Y))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCog-nScf354"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "x1 = np.random.normal(0,15,1000)\n",
        "y1 = np.random.normal(0,15,1000)\n",
        "x2 = np.random.normal(0,15,1000)+100\n",
        "y2 = np.random.normal(0,15,1000)\n",
        "\n",
        "plt.scatter(x1,y1)\n",
        "plt.scatter(x2,y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF6tuj6Zg5sO"
      },
      "outputs": [],
      "source": [
        "data0 = list(zip(x1,y1))\n",
        "data1 = list(zip(x2,y2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVSx4FkFhCVH"
      },
      "outputs": [],
      "source": [
        "dataset = data0+data1\n",
        "labels = [0]*len(data0)+[1]*len(data1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFracKH1hTv1"
      },
      "outputs": [],
      "source": [
        "datasets = [dataset,labels]\n",
        "# datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhRn_vFchsRu"
      },
      "outputs": [],
      "source": [
        "X,Y = datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZCHxjx0hyuO"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vt-eiaih2wl"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0kF3i2RtIie"
      },
      "outputs": [],
      "source": [
        "X, Y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=1, cluster_std=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnY-972gtRc-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "X_df = pd.DataFrame(X, columns=['x1','x2'])\n",
        "y_df = pd.DataFrame(Y, columns=[\"class\"])\n",
        "frames = [X_df, y_df]\n",
        "data = pd.concat(frames, axis=1)\n",
        "sns.scatterplot(x=\"x1\", y=\"x2\", hue='class', data=data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9xj3Meliw-H"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pZqAOb_jMe_"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IcHbnyJjSTF"
      },
      "outputs": [],
      "source": [
        "w,b,log = LogisticRegressions(X_train,y_train,X_test,y_test,lr = 2e-3 , n = 3000 , momentum = True,gramma = 0.9)\n",
        "print(w,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOz6QDPkjlWH"
      },
      "outputs": [],
      "source": [
        "def predict(x,w,b):\n",
        "  return np.round(sigmoid(np.dot(w.T,x.T) +b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjL0EfzZphOW"
      },
      "outputs": [],
      "source": [
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pWdwpTDEjuxt",
        "outputId": "3746dcae-9f5c-424e-f486-519c158ac56c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-36c8f492f253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# model.fit(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# make predictions for the grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# yhat = y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# generate dataset\n",
        "# X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=1, cluster_std=3)\n",
        "y = Y\n",
        "# define bounds of the domain\n",
        "min1, max1 = X[:, 0].min()-1, X[:, 0].max()+1\n",
        "min2, max2 = X[:, 1].min()-1, X[:, 1].max()+1\n",
        "# define the x and y scale\n",
        "x1grid = np.arange(min1, max1, 0.1)\n",
        "x2grid = np.arange(min2, max2, 0.1)\n",
        "# create all of the lines and rows of the grid\n",
        "xx, yy = np.meshgrid(x1grid, x2grid)\n",
        "# flatten each grid to a vector\n",
        "r1, r2 = xx.flatten(), yy.flatten()\n",
        "r1, r2 = r1.reshape((len(r1), 1)), r2.reshape((len(r2), 1))\n",
        "# horizontal stack vectors to create x1,x2 input for the model\n",
        "grid = np.hstack((r1,r2))\n",
        "# define the model\n",
        "# model = LogisticRegression()\n",
        "# fit the model\n",
        "# model.fit(X, y)\n",
        "# make predictions for the grid\n",
        "yhat = predict(grid,w,b)\n",
        "# yhat = y\n",
        "\n",
        "# reshape the predictions back into a grid\n",
        "zz = yhat.reshape(xx.shape)\n",
        "# plot the grid of x, y and z values as a surface\n",
        "plt.contourf(xx, yy, zz, cmap='Paired')\n",
        "# create scatter plot for samples from each class\n",
        "for class_value in range(2):\n",
        "    # get row indexes for samples with this class\n",
        "    row_ix = np.where(y == class_value)\n",
        "    # create scatter of these samples\n",
        "    plt.scatter(X[row_ix, 0], X[row_ix, 1], cmap='Paired')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e26c5386412dd47cde72cf8b7a71390e61e10f2d01548b0d0cb7f5cbd27e5d04"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
